---
layout:					post
title:					"LlamaIndex ollama æ­å»ºæœ¬åœ°RAGåº”ç”¨ï¼Œå»ºç«‹æœ¬åœ°çŸ¥è¯†åº“"
author:					Zhou Zhongqing
header-style:				text
catalog:					true
tags:
		- Web
		- JavaScript
---
@[TOC](ç›®å½•)
##   ç®€ä»‹
- ollamaï¼šæœ¬åœ°è¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥å…·è½¯ä»¶ã€‚ç”¨æˆ·å¯ä»¥è½»æ¾ä¸‹è½½ã€è¿è¡Œå’Œç®¡ç†å„ç§å¼€æº LLMã€‚é™ä½ä½¿ç”¨é—¨æ§›ï¼Œç”¨æˆ·èƒ½å¿«é€Ÿå¯åŠ¨è¿è¡Œæœ¬åœ°æ¨¡å‹ã€‚
- LlamaIndexï¼šç”¨æ¥è¿æ¥å¤§è¯­è¨€æ¨¡å‹å’Œå¤–éƒ¨æ•°æ®çš„æ¡†æ¶(å¤–éƒ¨æ•°æ®æŒ‡è‡ªèº«é¢†åŸŸçš„ç‰¹å®šçŸ¥è¯†)ï¼Œå®ƒå°†ä¸¤è€…ç»“åˆèµ·æ¥ï¼Œæå‡å›ç­”çš„å‡†ç¡®æ€§ã€‚


## å®‰è£…å‰çš„å‡†å¤‡
### ä¸‹è½½ollama
- ollamaå®˜æ–¹ä¸‹è½½åœ°å€ [https://ollama.com/download](https://ollama.com/download)  ,ç›®å‰æœ€æ–°ç‰ˆæ˜¯0.4.2ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/355066b053e6462b986da98e24c1d080.png)
### åˆ›å»ºllamaindex condaç¯å¢ƒï¼Œä¸ºåé¢ç¼–ç ä½œå‡†å¤‡
- ä¸ºå•¥è¦ç”¨condaå‘¢ï¼Ÿ
> åé¢è¦ç¼–ç ï¼Œè€ƒè™‘ä¸åŒé¡¹ç›®ä¾èµ–çš„pythonç‰ˆæœ¬å¯èƒ½ä¸åŒï¼Œç”¨condaæ¥ç®¡ç†,å¯ä»¥å¿«é€Ÿæ–°å¢pythonç¯å¢ƒï¼Œå¦‚æœç¯å¢ƒæç ¸äº†ï¼Œç”¨å‘½ä»¤åˆ é™¤ä¹Ÿå¾ˆæ–¹ä¾¿ã€‚

- condaä¸‹è½½åœ°å€ [https://www.anaconda.com/download/success](https://www.anaconda.com/download/success)
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/4f103edc1d6e4dbbb351af610f355c66.png)

## ç¯å¢ƒå˜é‡


| å‚æ•°                     | æ ‡è¯†ä¸é…ç½®                                                                                                                                                                                                                          |
| ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OLLAMA_MODELS            | è¡¨ç¤ºæ¨¡å‹æ–‡ä»¶çš„å­˜æ”¾ç›®å½•ï¼Œé»˜è®¤ç›®å½•ä¸º**å½“å‰ç”¨æˆ·ç›®å½•**å³  `C:\Users%username%.ollama\models`<br />Windows ç³»ç»Ÿ **å»ºè®®ä¸è¦æ”¾åœ¨Cç›˜**ï¼Œå¯æ”¾åœ¨å…¶ä»–ç›˜ï¼ˆå¦‚ `d:\software\ollama\models`ï¼‰                                             |
| OLLAMA_HOST              | è¡¨ç¤ºollama æœåŠ¡ç›‘å¬çš„ç½‘ç»œåœ°å€ï¼Œé»˜è®¤ä¸º**127.0.0.1** <br />å¦‚æœæƒ³è¦å…è®¸å…¶ä»–ç”µè„‘è®¿é—® Ollamaï¼ˆå¦‚å±€åŸŸç½‘ä¸­çš„å…¶ä»–ç”µè„‘ï¼‰ï¼Œ**å»ºè®®è®¾ç½®**æˆ **0.0.0.0**                                                                    |
| OLLAMA_PORT              | è¡¨ç¤ºollama æœåŠ¡ç›‘å¬çš„é»˜è®¤ç«¯å£ï¼Œé»˜è®¤ä¸º**11434** <br />å¦‚æœç«¯å£æœ‰å†²çªï¼Œå¯ä»¥ä¿®æ”¹è®¾ç½®æˆå…¶ä»–ç«¯å£ï¼ˆå¦‚**8080**ç­‰ï¼‰                                                                                                            |
| OLLAMA_ORIGINS           | è¡¨ç¤ºHTTP å®¢æˆ·ç«¯çš„è¯·æ±‚æ¥æºï¼Œä½¿ç”¨åŠè§’é€—å·åˆ†éš”åˆ—è¡¨<br />å¦‚æœæœ¬åœ°ä½¿ç”¨ä¸å—é™åˆ¶ï¼Œå¯ä»¥è®¾ç½®æˆæ˜Ÿå· `*`                                                                                                                                     |
| OLLAMA_KEEP_ALIVE        | è¡¨ç¤ºå¤§æ¨¡å‹åŠ è½½åˆ°å†…å­˜ä¸­åçš„å­˜æ´»æ—¶é—´ï¼Œé»˜è®¤ä¸º**5m**å³ 5 åˆ†é’Ÿ<br />ï¼ˆå¦‚çº¯æ•°å­—300 ä»£è¡¨ 300 ç§’ï¼Œ0 ä»£è¡¨å¤„ç†è¯·æ±‚å“åº”åç«‹å³å¸è½½æ¨¡å‹ï¼Œä»»ä½•è´Ÿæ•°åˆ™è¡¨ç¤ºä¸€ç›´å­˜æ´»ï¼‰<br />å»ºè®®è®¾ç½®æˆ **24h** ï¼Œå³æ¨¡å‹åœ¨å†…å­˜ä¸­ä¿æŒ 24 å°æ—¶ï¼Œæé«˜è®¿é—®é€Ÿåº¦ |
| OLLAMA_NUM_PARALLEL      | è¡¨ç¤ºè¯·æ±‚å¤„ç†çš„å¹¶å‘æ•°é‡ï¼Œé»˜è®¤ä¸º**1** ï¼ˆå³å•å¹¶å‘ä¸²è¡Œå¤„ç†è¯·æ±‚ï¼‰<br />å»ºè®®æŒ‰ç…§å®é™…éœ€æ±‚è¿›è¡Œè°ƒæ•´                                                                                                                                   |
| OLLAMA_MAX_QUEUE         | è¡¨ç¤ºè¯·æ±‚é˜Ÿåˆ—é•¿åº¦ï¼Œé»˜è®¤å€¼ä¸º**512** <br />å»ºè®®æŒ‰ç…§å®é™…éœ€æ±‚è¿›è¡Œè°ƒæ•´ï¼Œè¶…è¿‡é˜Ÿåˆ—é•¿åº¦çš„è¯·æ±‚ä¼šè¢«æŠ›å¼ƒ                                                                                                                                  |
| OLLAMA_DEBUG             | è¡¨ç¤ºè¾“å‡º Debug æ—¥å¿—ï¼Œåº”ç”¨ç ”å‘é˜¶æ®µå¯ä»¥è®¾ç½®æˆ**1** ï¼ˆå³è¾“å‡ºè¯¦ç»†æ—¥å¿—ä¿¡æ¯ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜ï¼‰                                                                                                                                        |
| OLLAMA_MAX_LOADED_MODELS | è¡¨ç¤ºæœ€å¤šåŒæ—¶åŠ è½½åˆ°å†…å­˜ä¸­æ¨¡å‹çš„æ•°é‡ï¼Œé»˜è®¤ä¸º**1** ï¼ˆå³åªèƒ½æœ‰ 1 ä¸ªæ¨¡å‹åœ¨å†…å­˜ä¸­ï¼‰                                                                                                                                                |

- æ³¨æ„ä¸‹`OLLAMA_HOST`ï¼Œå¥½åƒä¼šè‡ªåŠ¨åˆ›å»ºç”¨æˆ·ç¯å¢ƒå˜é‡ã€‚æœ¬åœ°ç›´æ¥ç”¨`127.0.0.1`ã€‚æ–¹ä¾¿è°ƒè¯•ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/e49d2391241c4af3bf2b8866f395e225.png)

- `OLLAMA_MODELS`ç¯å¢ƒå»ºè®®é…ç½®ä¸€ä¸‹ï¼Œé»˜è®¤æ˜¯åœ¨Cç›˜ï¼Œä¸€ä¸ªæ¨¡å‹ä¸€èˆ¬æ˜¯å‡ ä¸ªGã€‚æ¯”è¾ƒå ç”¨ç©ºé—´ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/87ccfd87f64e496290df758e4d4eb93f.png)


## è¿ç§»ollamaåˆ°å…¶ä»–ç›˜
- ç”±äºollamaæ˜¯ç›´æ¥å®‰è£…åœ¨Cç›˜ï¼ŒCç›˜å¦‚æœç©ºé—´ç´§å¼ ï¼Œå¯ä»¥åƒæˆ‘ä¸€æ ·è¿ç§»åˆ°Dç›˜ï¼Œå¦‚æœè§‰å¾—æ²¡æœ‰å¿…è¦ï¼Œå¯å¿½ç•¥æ­¤æ­¥éª¤ã€‚
- - æ–¹æ³•å°±æ˜¯åœ¨Cç›˜åˆ›å»ºè½¯é“¾æ¥ï¼Œå°†çœŸæ˜¯æ•°æ®æ”¾åˆ°Dç›˜ã€‚
> Administrator   æ˜¯æˆ‘çš„ç”¨æˆ·å
```bash
mklink /D C:\Users\Administrator\.ollama D:\software\Ollama\.ollama
mklink /D C:\Users\Administrator\AppData\Local\Ollama D:\software\Ollama\log
mklink /D C:\Users\Administrator\AppData\Local\Programs\Ollama D:\software\Ollama\app
```

- è¿ç§»åçš„ç»“æœ
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/f3d581334ee94912b8da5c91774863a9.png)
## è¿è¡Œollama 
### æ–¹å¼ä¸€
- åœ¨ç¨‹åºæ ä¸­æ‰¾åˆ°
 ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/a59d17d777464042b5551aaf76cebd24.png)
 ç‚¹å‡»å°±ä¼šè¿è¡Œã€‚ç„¶åå³ä¸‹è§’ä¼šå‡ºç°ollamaçš„å°å›¾æ ‡ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/e47724a126d0466a9a7bc503063ca481.png)

### æ–¹å¼äºŒ
- åœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥ `ollama serve` (æˆ‘æ²¡æœ‰ç‹¬æ˜¾ï¼Œæ˜¯ä»¥CPUæ–¹å¼è¿è¡Œçš„)
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/3daa1d016c7c48b09a82fa99fcbc48e8.png)



### ç¦æ­¢ollamaå¼€æœºè‡ªå¯åŠ¨
- å¦‚æœä¸æƒ³è®©ollamaå¼€æœºè‡ªå¯åŠ¨ï¼Œæ‰“å¼€ä»»åŠ¡ç®¡ç†å™¨ï¼Œ åˆ° `å¯åŠ¨` æ ç›®ï¼Œé€‰ä¸­å³é”® -> ç¦ç”¨æ­¢è‡ªå¯åŠ¨ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/806ba68de8054368ae4586f464b30b80.png)
### è¿è¡Œç¬¬ä¸€ä¸ªæ¨¡å‹
- æ‰“å¼€[https://ollama.com/](https://ollama.com/) ç½‘ç«™åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥`qwen`ã€‚è¿›å…¥`qwen2.5-coder`,`coder`è¡¨ç¤ºå¯¹ç¼–ç¨‹æ–¹é¢çš„é—®é¢˜æœ‰ä¼˜åŒ–ã€‚![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/0afc99cd81974e38abfd7e68ab5277a1.png)
- åœ¨è¯¦æƒ…é¡µé¢å¯ä»¥çœ‹åˆ°å„ç§ç‰ˆæœ¬tagã€‚å¯ä»¥æ ¹æ®è‡ªèº«ç”µè„‘é…ç½®æƒ…å†µä½¿ç”¨å“ªä¸€ä¸ªã€‚ä¸€èˆ¬æ¥è¯´æ¨¡å‹è¶Šå¤§å°±è¶Šæ¶ˆè€—èµ„æºã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/5de9492e947d4e2ba697654905758207.png)
- æˆ‘é€‰æ‹©çš„æ˜¯å½“å‰æœ€æ–°ç‰ˆæœ¬ã€‚è¿è¡Œçš„å‘½ä»¤æ˜¯ã€‚å¦‚ä½•æ²¡æœ‰å°±ä¼šå…ˆä¸‹è½½ã€‚

```
ollama run qwen2.5-coder
```
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/6a149cb16f0f42cb97faa11cf2af764c.png)
- è¿è¡Œåçš„ç•Œé¢å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/e954242583c04f639d60a622ef556c5f.png)
- ç„¶åæˆ‘ä»¬è¾“å…¥ä¸€ä¸ªé—®é¢˜ï¼ŒéªŒè¯æ˜¯å¦æˆåŠŸã€‚`13.8ä¸13.11å“ªä¸ªå¤§ï¼Ÿ`
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/bdaa035be9ea4e2cab601de3bbe9e91c.png)
- å¯ä»¥çœ‹å‡ºç­”æ¡ˆæ­£ç¡®ï¼Œå®‰è£…æˆåŠŸäº†ã€‚


## ChatboxèŠå¤©
- é¢å¯¹CMDçš„çª—å£èŠå¤©ä½“éªŒä¸å¤ªå¥½ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨ä¸€ä¸‹Chatboxè½¯ä»¶ã€‚
### ä¸‹è½½Chatbox
- ä¸‹è½½åœ°å€ [https://chatboxai.app/en](https://chatboxai.app/en)
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/7544e4eb85e7426d9df666c90c8c662f.png)


### é…ç½®ollamaåœ°å€å’Œæ¨¡å‹
- ç¬¬ä¸€ä¸ªä¸‹æ‹‰æ¡†é€‰æ‹© ollama ï¼Œ ä¸‹é¢çš„ä¸‹æ‹‰æ¡†é€‰åœ°å€å’Œæ¨¡å‹é…ç½®ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/85a461581fd8457baf024393609b2437.png)

### éªŒè¯
- æˆ‘ä»¬è¾“å…¥ä¸€ä¸ªé—®é¢˜ï¼ŒéªŒè¯æ˜¯å¦æˆåŠŸã€‚`13.8ä¸13.11å“ªä¸ªå¤§ï¼Ÿ`
 
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/2e8148ef626b477fa5594670a8901111.png)
-  ç»“æœæ­£ç¡®ã€‚

- ç„¶åæˆ‘ä»¬å†è¯•ä¸€ä¸ªå†·é—¨é—®é¢˜`ä»‹ç»ä¸€ä¸‹CSDNåšä¸»æ„¤æ€’çš„è‹¹æœextæ“…é•¿ä»€ä¹ˆï¼Ÿ` ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/8ab6a6ba3cf54ebeb2e9743a1ada1051.png)
- å¯ä»¥çœ‹å‡ºè¿™ä¸ªé—®é¢˜å®ƒæ˜¯ä¸çŸ¥é“çš„ã€‚

## å»ºç«‹è‡ªèº«ç‰¹å®šçŸ¥è¯†æ•°æ®æ­é…å¤§è¯­è¨€æ¨¡å‹
- ä¸€èˆ¬å¯¹äºæ¨¡å‹ä¸çŸ¥é“æˆ–ä¸å‡†ç¡®çš„å›ç­”æœ‰ä¸¤ç§è§£å†³æ–¹æ¡ˆ
	- 1ã€æ¨¡å‹å¾®è°ƒã€‚
	- 2ã€å»ºç«‹è‡ªèº«ç‰¹å®šçŸ¥è¯†æ•°æ® + å¤§è¯­è¨€æ¨¡å‹
- å¯¹äºè¦æ±‚å‡†ç¡®åº¦ä¸æ˜¯å¾ˆé«˜çš„åœºæ™¯ä¸€èˆ¬ä¼šé‡‡ç”¨å»ºç«‹è‡ªèº«ç‰¹å®šçŸ¥è¯†æ•°æ®çš„æ–¹æ¡ˆã€‚æœ¬æ–‡è¦å®è·µçš„å°±æ˜¯è¿™ç§æ–¹æ¡ˆã€‚

### åˆ›å»ºé¡¹ç›®ç¯å¢ƒ

- åˆ©ç”¨condaåˆ›å»º
```bash
 conda create -n llamaindex python=3.10.13
 conda activate  llamaindex
 #  å®‰è£…ä¾èµ–
pip install llama-index
pip install llama-index-llms-ollama
pip install llama-index-embeddings-ollama
pip install llama-index-readers-file
```

- å¦‚æœä¸çŸ¥é“æ€ä¹ˆåœ¨pycharmä¸­åº”ç”¨condaç¯å¢ƒï¼Œå¯ä»¥çœ‹æˆ‘è¿™ç¯‡æ–‡ç«  [https://blog.csdn.net/baidu_19473529/article/details/143442416](https://blog.csdn.net/baidu_19473529/article/details/143442416)ï¼Œå°±ä¸å†èµ˜è¿°ã€‚

- æ‹‰å–åµŒå…¥æ¨¡å‹.

```python
ollama pull quentinz/bge-small-zh-v1.5
```

### ä»£ç  
- test.py

```python
 
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.ollama import Ollama
from llama_index.core.node_parser import SentenceSplitter
import logging
import sys

# å¢åŠ æ—¥å¿—ä¿¡æ¯
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))
# é…ç½® åµŒå…¥æ¨¡å‹/é¢„è®­ç»ƒï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨quentinz/bge-small-zh-v1.5
from llama_index.embeddings.ollama import OllamaEmbedding
Settings.embed_model = OllamaEmbedding(model_name="quentinz/bge-small-zh-v1.5")
# é…ç½®ollamaçš„LLMæ¨¡å‹ï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨qwen2.5-coder
Settings.llm = Ollama(model="qwen2.5-coder", request_timeout=600.0)

#ç‰¹å®šçŸ¥è¯†æ•°æ®
data_file = ['D:/work/self/Llamaindex-sample/data/a.txt']
documents = SimpleDirectoryReader(input_files=data_file).load_data()
index = VectorStoreIndex.from_documents(documents, transformations=[SentenceSplitter(chunk_size=256)])

query_engine = index.as_query_engine(similarity_top_k=5)
response = query_engine.query("ä»‹ç»ä¸€ä¸‹CSDNåšä¸»æ„¤æ€’çš„è‹¹æœextæ“…é•¿ä»€ä¹ˆï¼Ÿ")
print(response)

```


- ç‰¹å®šçŸ¥è¯†æ•°æ®å†…å®¹ a.txt

```python
 CSDNåšä¸»æ„¤æ€’çš„è‹¹æœextæ“…é•¿Aiã€Fwã€Flã€Brã€Aeã€Prã€Idã€Psç­‰è½¯ä»¶çš„å®‰è£…ä¸å¸è½½ï¼Œç²¾é€šCSSã€JavaScriptã€PHPã€ASPã€Cã€Cï¼‹ï¼‹ã€C#ã€Javaã€Rubyã€Perlã€Lispã€pythonã€Objective-Cã€ActionScriptã€Pascalç­‰å•è¯çš„æ‹¼å†™ï¼Œç†Ÿæ‚‰Windowsã€Linuxã€Macã€Androidã€IOSã€WP8ç­‰ç³»ç»Ÿçš„å¼€å…³æœºã€‚
```
###  è¿è¡Œç»“æœ
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/674f065340ee424b95c375a4eba28252.png)
- å¯ä»¥çœ‹å‡ºç°åœ¨çš„è¿è¡Œç»“æœåŸºæœ¬ä¸Šå°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç»“æœäº†ã€‚

### streamlitåº”ç”¨
- é€šè¿‡ç¡¬ç¼–ç çš„æ–¹å¼å»é—®ç­”æ²¡æœ‰å›¾å½¢åŒ–ç•Œé¢æ–¹ä¾¿ï¼Œä¸‹é¢å¼•å…¥streamlitå°±èƒ½å¾—åˆ°å¹²å‡€å¥½çœ‹çš„Webé—®ç­”ç•Œé¢äº†ï¼Œ

- å‘½ä»¤è¡Œè¿è¡Œ

```python
 pip install streamlit
```

- ä»£ç  app.py

```python
import streamlit as st
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.llms.ollama import Ollama
from llama_index.core.memory import ChatMemoryBuffer
import os
import tempfile
import hashlib

# OLLAMA_NUM_PARALLELï¼šåŒæ—¶å¤„ç†å•ä¸ªæ¨¡å‹çš„å¤šä¸ªè¯·æ±‚
# OLLAMA_MAX_LOADED_MODELSï¼šåŒæ—¶åŠ è½½å¤šä¸ªæ¨¡å‹
os.environ['OLLAMA_NUM_PARALLEL'] = '2'
os.environ['OLLAMA_MAX_LOADED_MODELS'] = '2'


# Function to handle file upload
def handle_file_upload(uploaded_files):
    if uploaded_files:
        temp_dir = tempfile.mkdtemp()
        for uploaded_file in uploaded_files:
            file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getvalue())
        return temp_dir
    return None


# Function to calculate a hash for the uploaded files
def get_files_hash(files):
    hash_md5 = hashlib.md5()
    for file in files:
        file_bytes = file.read()
        hash_md5.update(file_bytes)
    return hash_md5.hexdigest()


# Function to prepare generation configuration
def prepare_generation_config():
    with st.sidebar:
        st.sidebar.header("Parameters")
        max_length = st.slider('Max Length', min_value=8, max_value=5080, value=4056)
        temperature = st.slider('Temperature', 0.0, 1.0, 0.7, step=0.01)
        st.button('Clear Chat History', on_click=clear_chat_history)

    generation_config = {
        'num_ctx': max_length,
        'temperature': temperature
    }
    return generation_config


# Function to clear chat history
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„åŠ©æ‰‹ï¼Œä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ"}]


# File upload in the sidebar
st.sidebar.header("Upload Data")
uploaded_files = st.sidebar.file_uploader("Upload your data files:", type=["txt", "pdf", "docx"],
                                          accept_multiple_files=True)

generation_config = prepare_generation_config()


# Function to initialize models
@st.cache_resource
def init_models():
    embed_model = OllamaEmbedding(model_name="quentinz/bge-small-zh-v1.5")
    Settings.embed_model = embed_model

    llm = Ollama(model="qwen2.5-coder", request_timeout=360.0,
                 num_ctx=generation_config['num_ctx'],
                 temperature=generation_config['temperature'])
    Settings.llm = llm

    documents = SimpleDirectoryReader(st.session_state['temp_dir']).load_data()
    index = VectorStoreIndex.from_documents(documents)

    memory = ChatMemoryBuffer.from_defaults(token_limit=4000)
    chat_engine = index.as_chat_engine(
        chat_mode="context",
        memory=memory,
        system_prompt="You are a chatbot, able to have normal interactions.",
    )

    return chat_engine


# Streamlit application
st.title("ğŸ’» Local RAG Chatbot ğŸ¤–")
st.caption("ğŸš€ A RAG chatbot powered by LlamaIndex and Ollama ğŸ¦™.")

# Initialize hash for the current uploaded files
current_files_hash = get_files_hash(uploaded_files) if uploaded_files else None

# Detect if files have changed and init models
if 'files_hash' in st.session_state:
    if st.session_state['files_hash'] != current_files_hash:
        st.session_state['files_hash'] = current_files_hash
        if 'chat_engine' in st.session_state:
            del st.session_state['chat_engine']
            st.cache_resource.clear()
        if uploaded_files:
            st.session_state['temp_dir'] = handle_file_upload(uploaded_files)
            st.sidebar.success("Files uploaded successfully.")
            if 'chat_engine' not in st.session_state:
                st.session_state['chat_engine'] = init_models()
        else:
            st.sidebar.error("No uploaded files.")
else:
    if uploaded_files:
        st.session_state['files_hash'] = current_files_hash
        st.session_state['temp_dir'] = handle_file_upload(uploaded_files)
        st.sidebar.success("Files uploaded successfully.")
        if 'chat_engine' not in st.session_state:
            st.session_state['chat_engine'] = init_models()
    else:
        st.sidebar.error("No uploaded files.")

# Initialize chat history
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„åŠ©æ‰‹ï¼Œä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ"}]

# Display chat messages from history
for message in st.session_state.messages:
    with st.chat_message(message['role'], avatar=message.get('avatar')):
        st.markdown(message['content'])

# Display chat input field at the bottom
if prompt := st.chat_input("Ask a question about Datawhale:"):

    with st.chat_message('user'):
        st.markdown(prompt)

    # Generate response
    print("st.session_state ",st.session_state)
    response = st.session_state['chat_engine'].stream_chat(prompt)
    with st.chat_message('assistant'):
        message_placeholder = st.empty()
        res = ''
        for token in response.response_gen:
            res += token
            message_placeholder.markdown(res + 'â–Œ')
        message_placeholder.markdown(res)

    # Add messages to history
    st.session_state.messages.append({
        'role': 'user',
        'content': prompt,
    })
    st.session_state.messages.append({
        'role': 'assistant',
        'content': response,
    })
```

- è¿è¡Œapp.pyçš„å‘½ä»¤

```bash
  streamlit run app.py
```

- è¿è¡Œåå°†è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨é¡µé¢
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/7cf444fac68f47d6ae30f3fe51bed9e5.png)

- å¯åŠ¨å®Œæˆåï¼Œé¦–å…ˆä¸Šä¼ å¤–éƒ¨æ•°æ®ï¼Œåˆå§‹åŒ–æ¨¡å‹ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/23a166fc5891409db39390b80c072408.png)
- å†æé—®éªŒè¯æ˜¯å¦æˆåŠŸã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/59c2055dbea04a88b8de0556dd3525d2.png)
- ä¸å‰é¢çš„å›ç­”å·®ä¸å¤šå°±è¡¨ç¤ºæˆåŠŸäº†ã€‚

## æœ¬æ–‡æ‰€ä½¿ç”¨çš„æºç åœ°å€

- [https://github.com/1030907690/Llamaindex-sample](https://github.com/1030907690/Llamaindex-sample)


## å‚è€ƒ

- https://juejin.cn/post/7418086006114713619
- https://blog.llyth.cn/1555.html
- https://www.bilibili.com/opus/978763969531478024
- https://github.com/datawhalechina/handy-ollama/blob/main/notebook/C7/LlamaIndex_RAG/%E4%BD%BF%E7%94%A8LlamaIndex%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0RAG%E5%BA%94%E7%94%A8.ipynb




















